# Taller 3 ‚Äî Taller Integral de Computaci√≥n Visual
**Fecha:** 2025-11-07  
**Integrantes:** Javier Giraldo, Miguel Martinez, Brayan Rubiano, Jes√∫s Qui√±ones.

---



## Descripci√≥n general

Este taller integral busca **dise√±ar y curar experiencias visuales interactivas** que integren diferentes componentes del pipeline gr√°fico y sensorial.
Los ejercicios combinan modelado 3D, materiales PBR, shaders personalizados, texturas din√°micas, interacci√≥n multimodal (voz, gestos, EEG) y control de c√°mara o entorno.

El objetivo es conectar percepci√≥n visual, f√≠sica de la luz, geometr√≠a procedural y comunicaci√≥n humano‚Äìm√°quina, consolidando las habilidades de integraci√≥n entre arte, c√≥digo y percepci√≥n.

---

## Actividades desarrolladas

### 1. Materiales, luz y color (PBR y modelos crom√°ticos)
- Implementaci√≥n de texturas PBR (albedo, roughness, metalness, normal map).
- Iluminaci√≥n m√∫ltiple (key, fill, rim, HDRI).
- C√°maras: alternancia entre perspectiva y ortogr√°fica.
- Paletas RGB/HSV y contraste en CIELAB.
- Animaciones demostrando variaciones de luz y material.

### 2. Modelado procedural desde c√≥digo
- Generaci√≥n algor√≠tmica de geometr√≠a (rejillas, espirales, fractales simples).
- Uso de bucles y recursi√≥n para patrones espaciales.
- Transformaciones din√°micas de v√©rtices.
- Comparativa entre modelado por c√≥digo y manual.

### 3. Shaders personalizados y efectos
- Implementaci√≥n de shaders b√°sicos (GLSL, HLSL, Shader Graph).
- Color din√°mico por posici√≥n, tiempo o interacci√≥n.
- Efectos de toon shading, wireframe, distorsi√≥n UV y gradientes.
- Texturizado procedural y mezcla de mapas din√°micos.

### 4. Texturizado din√°mico y part√≠culas
- Materiales reactivos a tiempo o entradas del usuario.
- Mapas animados: emissive, normal, offset UV, ruido procedural.
- Integraci√≥n de sistemas de part√≠culas sincronizados con shaders.
- Evento visual coordinado shader + part√≠culas.

### 5. Visualizaci√≥n de im√°genes y video 360¬∞
- Implementaci√≥n de skybox o esfera invertida para escenas 360¬∞.
- Uso de video equirectangular como textura din√°mica.
- Conmutaci√≥n entre panoramas o escenas.
- Control de c√°mara (orbit, giroscopio, entrada de usuario).

### 6. Entrada e interacci√≥n (UI, input y colisiones)
- Captura de teclado, mouse y touch.
- Uso de UI Canvas o HTML para interacci√≥n visual.
- Colisiones f√≠sicas o triggers que disparan efectos.
- Sincronizaci√≥n de eventos visuales con acciones del usuario.

### 7. Gestos con c√°mara web (MediaPipe Hands)
- Detecci√≥n de manos en tiempo real con MediaPipe + OpenCV.
- Conteo de dedos, detecci√≥n de gestos y distancias.
- Mapeo de gestos a acciones visuales.
- Implementaci√≥n de minijuego o interfaz gestual.

### 8. Reconocimiento de voz y control por comandos
- Captura de audio con SpeechRecognition/PyAudio.
- Reconocimiento local o online.
- Diccionario de comandos y acciones visuales.
- Integraci√≥n con Unity o Processing mediante OSC.
- Retroalimentaci√≥n auditiva con pyttsx3.

### 9. Interfaces multimodales (voz + gestos)
- Integraci√≥n simult√°nea de voz y gestos.
- Sincronizaci√≥n de hilos y eventos.
- L√≥gica condicional para acciones combinadas.
- Interfaz visual reactiva con retroalimentaci√≥n.

### 10. Simulaci√≥n BCI (EEG sint√©tico y control)
- Generaci√≥n de se√±ales EEG sint√©ticas (bandas Alpha/Beta).
- Filtros pasa banda y umbrales de activaci√≥n.
- Control visual a partir de variaciones EEG.
- Interfaz interactiva con PyGame o Tkinter.

### 11. Espacios proyectivos y matrices de proyecci√≥n
- Uso de coordenadas homog√©neas y proyecciones.
- Implementaci√≥n de matrices ortogr√°ficas y perspectiva.
- Visualizaci√≥n de profundidad y alternancia de c√°maras.

---

## Herramientas utilizadas
- **Unity (versi√≥n LTS)**
- **Three.js / React Three Fiber**
- **Python (Colab o local)**
- **Processing (2D/3D)**
- **Librer√≠as y complementos:** MediaPipe, SpeechRecognition, OSC, OpenCV, PyGame, Tkinter.

---

## Resultados esperados
- 6 capturas de escenas distintas.
- 6 GIFs mostrando interacci√≥n y shaders din√°micos.
- 1 video (30‚Äì60 s) de la experiencia completa.
- C√≥digo ejecutable y documentado.

---

## Criterios de evaluaci√≥n

| Criterio                                | Descripci√≥n                                   | Peso |
| --------------------------------------- | --------------------------------------------- | ---- |
| Organizaci√≥n                            | Estructura de carpetas y README claros        | 10%  |
| Modelado y geometr√≠a procedural         | Generaci√≥n y coherencia de formas             | 10%  |
| Materiales e iluminaci√≥n PBR            | Realismo, coherencia y respuesta a la luz     | 15%  |
| Shaders y texturizado din√°mico          | Efectos visuales y complejidad t√©cnica        | 15%  |
| Interacci√≥n multimodal (voz/gestos/EEG) | Integraci√≥n funcional y creativa              | 15%  |
| C√°maras y proyecci√≥n                    | Uso correcto de perspectiva/orto y movimiento | 10%  |
| Animaciones y part√≠culas                | Movimiento expresivo, sincronizaci√≥n visual   | 10%  |
| Evidencias visuales                     | GIFs, videos y capturas claras                | 10%  |
| C√≥digo y documentaci√≥n                  | Claridad, comentarios y commits en ingl√©s     | 5%   |
| **Total**                               |                                               | **100%** |

---

# Subproyecto: Geometr√≠a Procedural, Shaders y Espacios Proyectivos

## Estructura

```
2025-11-07_taller_3_integrado_computacion_visual/
‚îú‚îÄ‚îÄ renders/                 #Generated GIFs & Images.
‚îú‚îÄ‚îÄ unity/
    ‚îú‚îÄ‚îÄ T3_Int_Sec_2_3_11/   #Folder with Unity Scene objects and structure
        ‚îú‚îÄ‚îÄ Assets/
           ‚îú‚îÄ‚îÄ Materials/    #Procedural Material.
           ‚îú‚îÄ‚îÄ Scripts/      #Game Object procedural behaviour gen & Camera Projection Switch.
           ‚îú‚îÄ‚îÄ Shaders/      #HLSL Custom Procedural Shader.
‚îú‚îÄ‚îÄ README.md                #You are here man.
```

#### Implementaci√≥n: Brayan Rubiano
## IMPORTANTE: [Enlace implementaci√≥n subproyecto completa](https://github.com/brubianop/VisualComputingUN2025II/tree/main/2025-11-07_Taller_3_Integrado)
Este documento describe la implementaci√≥n de t√©cnicas de gr√°ficos por computadora en Unity (Universal Render Pipeline, URP), enfoc√°ndose en la generaci√≥n de geometr√≠a din√°mica y shaders procedurales.

![Procedural Wave](./renders/T3_Procedural_Shaders_Projections.gif)

![Procedural Wave](./renders/T3_ProceduralWave_Perspective.png)

![Procedural Wave](./renders/T3_ProceduralWave_Orthographic.png)

---

## 1. Introducci√≥n

El objetivo de este proyecto es demostrar las capacidades de la **Generaci√≥n Procedural en CPU** (C#) y el **Renderizado Procedural en GPU** (HLSL) para crear un efecto de onda din√°mica y coloreada.

---

## 2. Secciones Implementadas

El proyecto aborda y completa las siguientes secciones del taller:

| Secci√≥n | Tema | Implementaci√≥n |
| :--- | :--- | :--- |
| **Secci√≥n 2** | **Geometr√≠a Procedural (CPU)** | Generaci√≥n de una malla de plano din√°mica. Deformaci√≥n en tiempo real de los v√©rtices (altura **Y**) usando una funci√≥n **senoidal 1D** (`ProceduralWaveGen.cs`). |
| **Secci√≥n 3 & 4** | **Shaders Procedurales (GPU)** | Implementaci√≥n de un *shader* URP en **HLSL** (`ProceduralURPHLSL.shader`). El color se calcula en el *Fragment Shader* bas√°ndose en la **posici√≥n mundial** (`positionWS`) y el **tiempo** (`_Time.y`). |
| **Secci√≥n 11** | **Proyecci√≥n de C√°mara** | Control de la vista de la c√°mara, permitiendo el *toggle* entre proyecciones `Perspectiva` y `Ortografica` (Barra Espaciadora commo *Trigger*). |


## 3. Componentes Clave del C√≥digo

| Archivo | Objeto Asignado | Funci√≥n Principal |
| :--- | :--- | :--- |
| **`ProceduralWaveGen.cs`** | `ProceduralWave` | Genera la malla (`Mesh`), almacena las posiciones base (`baseVertices`), y calcula la deformaci√≥n de la onda en `Update()`. |
| **`ProceduralURPHLSL.shader`** | `ProceduralMat` | Contiene el c√≥digo HLSL para calcular el color din√°mico y el mapeo. |
| **`CameraSwitch.cs`** | `Main Camera` | Fija la posici√≥n de c√°mara inicial y gestiona el *toggle* de proyecci√≥n al presionar la **Barra Espaciadora**. |

## 4. C√≥digo Relevante
#### `ProceduralWaveGen.cs`
```csharp
void CreateProceduralMesh()
{
    // Vertex and UV gen
    List<Vector3> vertices = new List<Vector3>();
    List<Vector2> uvs = new List<Vector2>();

    for (int i = 0; i <= resolution; i++)
    {
        for (int j = 0; j <= resolution; j++)
        {
            // Vertex pos. Center at (0, 0, 0)
            float x = (float)i / resolution * size - size / 2f;
            float z = (float)j / resolution * size - size / 2f;
            vertices.Add(new Vector3(x, 0, z));
            uvs.Add(new Vector2((float)i / resolution, (float)j / resolution));
        }
    }
    mesh.vertices = vertices.ToArray();
    mesh.uv = uvs.ToArray();

    // Triangle gen -> Quad gen.
    List<int> triangles = new List<int>();
    for (int i = 0; i < resolution; i++)
    {
        for (int j = 0; j < resolution; j++)
        {
            int a = i * (resolution + 1) + j;
            int b = a + 1;
            int c = (i + 1) * (resolution + 1) + j;
            int d = c + 1;

            // Quad triangulation
            triangles.Add(a); triangles.Add(c); triangles.Add(b);
            triangles.Add(b); triangles.Add(c); triangles.Add(d);
        }
    }
    mesh.triangles = triangles.ToArray();
    mesh.RecalculateNormals();
}

void Update()
{
    if (baseVertices == null || baseVertices.Length == 0) return;

    currentVertices = mesh.vertices;

    for (int i = 0; i < currentVertices.Length; i++)
    {
        Vector3 basePos = baseVertices[i];

        // Wave behaviour. (Sine function used)
        float waveY = amplitude * Mathf.Sin(
            (basePos.x * frequency) + (Time.time * speed)
        );

        // New Height recalc.
        currentVertices[i] = new Vector3(basePos.x, waveY, basePos.z);
    }

    mesh.vertices = currentVertices;
    mesh.RecalculateNormals();
    mesh.RecalculateBounds();

}
```

#### `ProceduralURPHLSL.shader`
``` csharp
HLSLPROGRAM

#pragma vertex vert
#pragma fragment frag

#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

struct Attributes {
    float4 positionOS : POSITION;
};

struct Varyings {
    float4 positionCS : SV_POSITION;
    float3 positionWS : TEXCOORD0; // Vertex pos in World Space
};

CBUFFER_START(UnityPerMaterial)
    float4 _Color;
    float _Frequency;
    float _Speed;
CBUFFER_END

// Vertex Shader
Varyings vert (Attributes input) {
    Varyings output;
    output.positionCS = TransformObjectToHClip(input.positionOS.xyz);
    output.positionWS = TransformObjectToWorld(input.positionOS.xyz);

    return output;
}

// Fragment Shader (Procedural Color Calc.)
float4 frag (Varyings input) : SV_Target {

    float time = _Time.y;

    // Color given time and pos.
    float r_comp = sin(input.positionWS.x * _Frequency + time * _Speed);
    float g_comp = sin(input.positionWS.z * _Frequency * 1.5 + time * _Speed * 1.5);

    // Mapping. Normalization from [-1, 1] -> [0, 1] coords..
    float intensityR = r_comp * 0.5 + 0.5;
    float intensityG = g_comp * 0.5 + 0.5;
    float intensityB = input.positionWS.y * 0.1 + 0.5; // BLUE -. Height

    float4 proceduralColor = float4(intensityR, intensityG, intensityB, 1.0);

    // Mix Procedural Color and Base Color
    return proceduralColor * _Color;
}
ENDHLSL
```

#### `CameraSwitch.cs`
``` csharp
private Camera mainCamera;
void Start()
{
    mainCamera = GetComponent<Camera>();
    mainCamera.orthographic = false; // DEFAULT = PERSPECTIVE

    // Initial Camera pos.
    transform.position = new Vector3(25, 20, -30);
    transform.rotation = Quaternion.Euler(30, -45, 0);

    mainCamera.fieldOfView = 80;
}


void Update()
{
    // Camera Switch trigger = SpaceBar.
    if (Input.GetKeyDown(KeyCode.Space))
    {
        // Switch Projection
        mainCamera.orthographic = !mainCamera.orthographic;

        if (mainCamera.orthographic)
        {
            // Ortho adjustment. Size.
            mainCamera.orthographicSize = 18;
            Debug.Log("ORTHOGRAPHIC: (Sec. 11).");
        }
        else
        {
            Debug.Log("PERSPECTIVE:(Sec. 11).");
        }
    }
}
```

# Subproyecto: Materiales, Luz y Visualizaci√≥n 360¬∞

## **Propiedades Probadas**

### **1. Materiales, luz y color (PBR y modelos crom√°ticos)**
- **Texturas PBR:**
  - Propiedades: albedo, roughness, metalness.
  - Aplicaci√≥n de materiales din√°micos a objetos.
- **Iluminaci√≥n m√∫ltiple:**
  - Configuraci√≥n de luces Key, Fill y Rim.
  - Variaciones din√°micas de luz en la escena.
- **Paleta de colores din√°mica:**
  - Uso de un script personalizado para asignar colores.
  - Animaciones que demuestran cambios en tiempo real.

### **2. Visualizaci√≥n de im√°genes y video 360¬∞**
- **Esfera invertida:**
  - Creaci√≥n de una esfera con normales invertidas.
  - Uso de un shader personalizado para invertir las normales.
- **Textura equirectangular:**
  - Aplicaci√≥n de una imagen equirectangular como textura.
  - Configuraci√≥n de la c√°mara para explorar la imagen 360¬∞.

---
## **Implementaci√≥n:**

### **1. Materiales, luz y color (PBR y modelos crom√°ticos)**
- Se crearon materiales PBR con texturas b√°sicas y se asignaron a objetos 3D.
- Se configuraron luces direccionales (Key, Fill, Rim) para iluminar la escena.
- Se implement√≥ una paleta de colores din√°mica utilizando un script personalizado.
- Se animaron propiedades de materiales, como el color, para demostrar variaciones din√°micas.

### **5. Visualizaci√≥n de im√°genes y video 360¬∞**
- Se cre√≥ una esfera invertida para mostrar im√°genes equirectangulares.
- Se asign√≥ un material con un shader personalizado para invertir las normales.
- Se import√≥ y aplic√≥ una imagen equirectangular como textura al material.
- La c√°mara se posicion√≥ dentro de la esfera para explorar la imagen 360¬∞.

---

## Evidencias

### GIF de Iluminaci√≥n
- **Descripci√≥n**: Este GIF muestra c√≥mo las luces (Key, Fill y Rim) afectan a los materiales PBR en la escena al moverlas din√°micamente.
- **Ubicaci√≥n**: El archivo GIF se encuentra en la carpeta `renders/` con el nombre `iluminacion_dinamica.gif`.

```plaintext
renders/
‚îú‚îÄ‚îÄ iluminacion_dinamica.gif
```

### GIF Resumen del Taller
- **Descripci√≥n**: Este GIF muestra un resumen de las actividades realizadas en el taller, incluyendo:
  - Cambios din√°micos en materiales y luces.
  - Exploraci√≥n de la esfera invertida con imagen equirectangular.
- **Ubicaci√≥n**: El archivo GIF se encuentra en la carpeta `renders/` con el nombre `Taller3_Resumen.gif`.

```plaintext
renders/
‚îú‚îÄ‚îÄ iluminacion_dinamica.gif
‚îú‚îÄ‚îÄ Taller3_Resumen.gif
```

![Taller 3 Resumen](./renders/Taller3_Resumen.gif)
---

## Contribuciones Grupales

- **Miguel Martinez** ‚Äî Organizaci√≥n del repositorio inicial, desarrollo de los puntos 1 (Materiales, luz y color) y 5 (Visualizaci√≥n de im√°genes y video 360¬∞).

---
## Subproyecto: SnakeVision - Control Gestual Intuitivo

### Tecnolog√≠as Implementadas

- **Python 3.8+**: Lenguaje de programaci√≥n principal
- **OpenCV**: Procesamiento de im√°genes y video en tiempo real
- **MediaPipe Hands**: Detecci√≥n y seguimiento de landmarks de manos
- **NumPy**: Operaciones matem√°ticas y manejo de arrays
- **Conda**: Gesti√≥n de entorno y dependencias

### Descripci√≥n

SnakeVision es una implementaci√≥n moderna del cl√°sico juego Snake, donde el control se realiza mediante gestos de mano detectados por una c√°mara web. El proyecto combina visi√≥n por computadora con gaming tradicional, creando una experiencia de juego inmersiva y natural.

**Caracter√≠sticas principales:**
- Control gestual intuitivo sin hardware adicional
- Interfaz dividida: c√°mara en tiempo real + juego
- Sistema de puntuaci√≥n con crecimiento progresivo
- Detecci√≥n robusta de gestos con feedback visual
- Mec√°nicas de juego optimizadas para control gestual

### C√≥digos Destacados

#### 1. Sistema de Detecci√≥n de Gestos (`hand_gesture_controller.py`)

```python
def get_gesture(self, fingers):
    """Convierte el conteo de dedos en gestos para el juego"""
    count = sum(fingers)
    
    if count == 0:  # Pu√±o cerrado
        return "STOP"
    elif count == 1 and fingers[1] == 1:  # Solo √≠ndice
        return "UP"
    elif count == 2 and fingers[1] == 1 and fingers[2] == 1:  # √çndice y medio
        return "RIGHT"
    # ... m√°s gestos
```

**Importancia**: Este algoritmo traduce la configuraci√≥n de dedos en comandos de juego, usando landmarks espec√≠ficos de MediaPipe para determinar qu√© dedos est√°n extendidos.

#### 2. L√≥gica Principal del Juego (`snake_game.py`)

```python
def update(self, gesture):
    # Control de velocidad
    current_time = time.time()
    if current_time - self.last_update_time < self.game_speed:
        return
        
    # Mec√°nica de crecimiento al comer
    if new_head == self.food:
        self.score += 1
        self.food = self.generate_food()
        # NO remover la cola - la serpiente crece
    else:
        self.snake.pop()  # Solo remover cola si no comi√≥
```

**Importancia**: Implementa el n√∫cleo del juego con control de velocidad optimizado y la mec√°nica clave de crecimiento de la serpiente.

#### 3. Integraci√≥n y Visualizaci√≥n (`main.py`)

```python
# Procesamiento en tiempo real
annotated_frame, gesture = gesture_controller.process_frame(frame_resized)
snake_game.update(gesture)

# Interfaz dividida 1/3 - 2/3
combined_canvas = np.zeros((combined_height, combined_width, 3), dtype=np.uint8)
combined_canvas[cam_y_offset:cam_y_offset + target_cam_height, 0:target_cam_width] = annotated_frame
snake_game.draw(combined_canvas, x_offset=game_x_offset, y_offset=game_y_offset)
```

**Importancia**: Coordina todos los componentes y gestiona la interfaz de usuario unificada.

### Manejo de los Gestos

#### Mapeo Gestual ‚Üí Comandos

| Gesto | Dedos | Comando | Funci√≥n |
|-------|-------|---------|---------|
| üñêÔ∏è Mano abierta | 5 dedos | `START` | Iniciar/Reiniciar juego |
| ‚òùÔ∏è Solo √≠ndice | 1 dedo | `UP` | Mover hacia arriba |
| ‚úåÔ∏è √çndice + medio | 2 dedos | `RIGHT` | Mover hacia derecha |
| ü§ü √çndice + medio + anular | 3 dedos | `DOWN` | Mover hacia abajo |
| üññ 4 dedos | 4 dedos | `LEFT` | Mover hacia izquierda |
| ‚úä Pu√±o cerrado | 0 dedos | `STOP` | Pausar juego |
| ‚úä √ó 3 segundos | 0 dedos (hold) | `EXIT` | Salir del juego |

#### Algoritmo de Detecci√≥n

1. **Detecci√≥n de Landmarks**: MediaPipe identifica 21 puntos clave por mano
2. **An√°lisis de Posici√≥n**: Compara posiciones y-axis entre puntas y articulaciones
3. **Clasificaci√≥n de Gestos**: Cuenta dedos extendidos y mapea a comandos
4. **Suavizado**: Evita cambios bruscos manteniendo estado anterior

### Evidencias

Se evidencia el uso de los gestos tal como se observa a continuaci√≥n:
![python1](Python/evidencias/game.gif)
![python2](Python/evidencias/game2.gif)

El video completo se puede ver desde el documento 
**Ejemplos de evidencias a incluir:**
- Captura de pantalla mostrando la interfaz dividida
- GIF demostrando el control gestual en acci√≥n
- Secuencia de gestos reconocidos por el sistema
- Ejemplo de gameplay con aumento de puntuaci√≥n

### Conclusiones

#### Logros del Proyecto

1. **Control Intuitivo**: Se logr√≥ un sistema de control gestual natural que no requiere aprendizaje complejo
2. **Precisi√≥n en Detecci√≥n**: MediaPipe provee detecci√≥n robusta incluso en diferentes condiciones de iluminaci√≥n
3. **Rendimiento Optimizado**: El juego mantiene 60 FPS mientras procesa video en tiempo real
4. **Experiencia de Usuario**: La interfaz dividida permite verificar gestos mientras se juega

#### Desaf√≠os Superados

- **Sincronizaci√≥n**: Coordinar la velocidad de detecci√≥n con la velocidad del juego
- **Calibraci√≥n**: Ajustar sensibilidad para evitar detecciones falsas
- **Feedback Visual**: Proporcionar informaci√≥n clara sobre gestos detectados

#### Aplicaciones Futuras

El framework desarrollado puede extenderse para:
- Control de otras aplicaciones mediante gestos
- Sistemas de rehabilitaci√≥n con terapia gestual
- Interfaces para personas con movilidad reducida
- Juegos m√°s complejos con vocabulario gestual expandido

#### Impacto Tecnol√≥gico

SnakeVision demuestra que es posible crear experiencias interactivas completas usando √∫nicamente visi√≥n por computadora, eliminando la necesidad de controladores f√≠sicos y abriendo posibilidades para interfaces m√°s naturales e inclusivas.

#### Uso de IA
Se implement√≥ *Deepseek* principalmente para el desarrollo de la documentaci√≥n.


---

# Reflexi√≥n final

Este taller integra todos los componentes explorados durante el curso, conectando **percepci√≥n, interacci√≥n y visualizaci√≥n avanzada**.
El trabajo consolida una comprensi√≥n pr√°ctica del pipeline gr√°fico moderno, resaltando la importancia del dise√±o sensorial, la respuesta visual coherente y la documentaci√≥n t√©cnica reproducible.

---

## Estructura del repositorio

```plaintext
2025-10-17_taller_3_integrado_computacion_visual/
‚îú‚îÄ‚îÄ unity/           # Escenas y materiales PBR
‚îú‚îÄ‚îÄ threejs/         # Experimentos WebGL / R3F
‚îú‚îÄ‚îÄ python/          # Scripts de procesamiento o EEG
‚îú‚îÄ‚îÄ processing/      # Sketches visuales 2D/3D
‚îú‚îÄ‚îÄ renders/         # Capturas y GIFs
‚îú‚îÄ‚îÄ media/           # Videos o audios usados
‚îî‚îÄ‚îÄ README.md
```